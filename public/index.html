<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>AR con Imágenes Naturales</title>
    <script src="https://cdn.jsdelivr.net/npm/three@0.132.2/build/three.min.js"></script>
    <script src="https://raw.githack.com/AR-js-org/AR.js/master/three.js/build/ar-threex.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.132.2/examples/js/loaders/GLTFLoader.js"></script>
    <style>
      body {
        margin: 0;
        overflow: hidden;
      }
      #info {
        position: absolute;
        top: 10px;
        left: 10px;
        color: white;
        background: rgba(0, 0, 0, 0.5);
        padding: 10px;
        font-family: Arial;
      }
    </style>
  </head>
  <body>
    <div id="info">
      Apunte a una imagen con buen contraste (como un libro, revista o poster)
    </div>
    <script>
      // 1. Configuración inicial
      const scene = new THREE.Scene();
      const camera = new THREE.PerspectiveCamera(
        60,
        window.innerWidth / window.innerHeight,
        0.1,
        1000
      );
      const renderer = new THREE.WebGLRenderer({
        antialias: true,
        alpha: true,
      });
      renderer.setSize(window.innerWidth, window.innerHeight);
      document.body.appendChild(renderer.domElement);

      // 2. Configuración de AR.js para imágenes naturales
      const arToolkitSource = new THREEx.ArToolkitSource({
        sourceType: "webcam",
      });

      const arToolkitContext = new THREEx.ArToolkitContext({
        cameraParametersUrl:
          "https://raw.githack.com/AR-js-org/AR.js/master/data/data/camera_para.dat",
        detectionMode: "mono_natural", // Modo para imágenes naturales
        maxDetectionRate: 30,
        canvasWidth: 640,
        canvasHeight: 480,
      });

      // 3. Crear un controlador para el tracking natural
      const markerRoot = new THREE.Group();
      scene.add(markerRoot);

      // No necesitamos un patrón específico para el modo natural
      const arMarkerControls = new THREEx.ArMarkerControls(
        arToolkitContext,
        markerRoot,
        {
          type: "nft", // Usar NFT (Natural Feature Tracking)
          descriptorsUrl: "leon/solo-leon", // Ruta base para los descriptores
          changeMatrixMode: "cameraTransformMatrix",
        }
      );

      // 4. Añadir un modelo 3D
      const loader = new THREE.GLTFLoader();
      let model;

      loader.load(
        "models/patricio.glb",
        (glb) => {
          model = glb.scene;
          model.scale.set(0.5, 0.5, 0.5);
          model.position.y = 0.5;
          markerRoot.add(model);
        },
        undefined,
        (error) => {
          console.error("Error al cargar el modelo:", error);
        }
      );

      // 5. Añadir luz
      const light = new THREE.AmbientLight(0xffffff, 1.0);
      scene.add(light);
      const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
      directionalLight.position.set(1, 1, 1);
      scene.add(directionalLight);

      // 6. Bucle de renderizado
      function animate() {
        requestAnimationFrame(animate);

        if (model) {
          model.rotation.y += 0.01;
        }

        if (arToolkitSource.ready) {
          arToolkitContext.update(arToolkitSource.domElement);
          scene.visible = camera.visible;
        }

        renderer.render(scene, camera);
      }

      // 7. Inicialización
      arToolkitSource.init(() => {
        arToolkitContext.init(() => {
          camera.projectionMatrix.copy(arToolkitContext.getProjectionMatrix());
          animate();
        });
      });

      // 8. Manejar redimensionamiento
      window.addEventListener("resize", () => {
        camera.aspect = window.innerWidth / window.innerHeight;
        camera.updateProjectionMatrix();
        renderer.setSize(window.innerWidth, window.innerHeight);
      });
    </script>
  </body>
</html>
